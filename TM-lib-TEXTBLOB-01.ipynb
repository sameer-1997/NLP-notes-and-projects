{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U textblob\n",
    "# python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the import.\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "from textblob.wordnet import VERB\n",
    "\n",
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s create our first TextBlob object.\n",
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Python is a high-level, general-purpose programming language.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen = TextBlob(\"Beautiful is better than ugly. \"\n",
    "               \"Explicit is better than implicit. \"\n",
    "               \"Simple is better than complex.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Beautiful', 'is', 'better', 'than', 'ugly', 'Explicit', 'is', 'better', 'than', 'implicit', 'Simple', 'is', 'better', 'than', 'complex'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.words.count('is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Beautiful is better than ugly.\"),\n",
       " Sentence(\"Explicit is better than implicit.\"),\n",
       " Sentence(\"Simple is better than complex.\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words and noun phrase counts\n",
    "\n",
    "### Using word_counts dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "monty = TextBlob(\"We are no longer the Knights who say Ni. \"\n",
    "                 \"We are now the Knights who say Ekki ekki ekki PTANG.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'we': 2,\n",
       "             'are': 2,\n",
       "             'no': 1,\n",
       "             'longer': 1,\n",
       "             'the': 2,\n",
       "             'knights': 2,\n",
       "             'who': 2,\n",
       "             'say': 2,\n",
       "             'ni': 1,\n",
       "             'now': 1,\n",
       "             'ekki': 3,\n",
       "             'ptang': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.word_counts['ekki']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you access the frequencies this way, the search will not be case sensitive, and words that are not found will have a frequency of 0.\n",
    "\n",
    "The second way is to use the count() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.words.count('ekki', case_sensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.noun_phrases.count('we')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Inflection and Lemmatization\n",
    "\n",
    "Each word in TextBlob.words or Sentence.words is a Word object (a subclass of unicode) with useful methods, e.g. for word inflection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = TextBlob('Use 4 spaces per indentation level.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Use', '4', 'spaces', 'per', 'indentation', 'level'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'space'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'levels'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[-1].pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words can be lemmatized by calling the lemmatize method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word(\"octopi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word(\"went\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopi'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.lemmatize(\"v\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging\n",
    "\n",
    "Part-of-speech tags can be accessed through the tags property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen = TextBlob(\"Beautiful is better than ugly. \"\n",
    "               \"Explicit is better than implicit. \"\n",
    "               \"Simple is better than complex.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Beautiful', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('ugly', 'RB'),\n",
       " ('Explicit', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('implicit', 'NN'),\n",
       " ('Simple', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('complex', 'JJ')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful => NNP\n",
      "is => VBZ\n",
      "better => JJR\n",
      "than => IN\n",
      "ugly => RB\n",
      "Explicit => NNP\n",
      "is => VBZ\n",
      "better => JJR\n",
      "than => IN\n",
      "implicit => NN\n",
      "Simple => NN\n",
      "is => VBZ\n",
      "better => JJR\n",
      "than => IN\n",
      "complex => JJ\n"
     ]
    }
   ],
   "source": [
    "for word, pos in zen.tags:\n",
    "    print(word + \" => \" + pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Phrase Extraction\n",
    "\n",
    "noun phrases are accessed through the noun_phrases property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = (\"In computer science, artificial intelligence (AI), \\\n",
    "            sometimes called machine intelligence, is intelligence \\\n",
    "            demonstrated by machines, in contrast to the natural intelligence \\\n",
    "            displayed by humans and animals. Computer science defines AI \\\n",
    "            research as the study of \\\"intelligent agents\\\": any device that \\\n",
    "            perceives its environment and takes actions that maximize its\\\n",
    "            chance of successfully achieving its goals.[1] Colloquially,\\\n",
    "            the term \\\"artificial intelligence\\\" is used to describe machines\\\n",
    "            that mimic \\\"cognitive\\\" functions that humans associate with other\\\n",
    "            human minds, such as \\\"learning\\\" and \\\"problem solving\\\".[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blob_object = TextBlob(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer science\n",
      "artificial intelligence\n",
      "ai\n",
      "machine intelligence\n",
      "natural intelligence\n",
      "computer\n",
      "science defines\n",
      "ai\n",
      "intelligent agents\n",
      "colloquially\n",
      "artificial intelligence\n",
      "describe machines\n",
      "human minds\n"
     ]
    }
   ],
   "source": [
    "text_blob_object = TextBlob(document)\n",
    "for noun_phrase in text_blob_object.noun_phrases:\n",
    "    print(noun_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction\n",
    "Use the correct() method to attempt spelling correction.\n",
    "\n",
    "Spelling correction is based on Peter Norvig’s “How to Write a Spelling Corrector” as implemented in the pattern library. It is about 70% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"I havv goood speling!\")\n",
    "print(b.correct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word objects have a spellcheck() Word.spellcheck() method that returns a list of (word, confidence) tuples with spelling suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "w = Word('falibility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fallibility', 1.0)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation and Language Detection\n",
    "\n",
    "One of the most powerful capabilities of the TextBlob library is to translate from one language to another. On the backend, the TextBlob language translator uses the __Google Translate API__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_blob = TextBlob(u'Simple is better than complex.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Simple es mejor que complejo.\")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_blob.translate(to='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Beauty is better than ugly\")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_blob = TextBlob(u\"美丽优于丑陋\")\n",
    "chinese_blob.translate(from_lang=\"zh-CN\", to='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also attempt to detect a TextBlob’s language using TextBlob.detect_language()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ar'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(u\"بسيط هو أفضل من مجمع\")\n",
    "b.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bn'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(\"tumi kemon aachon\")\n",
    "b.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(u\"क्या हाल है\")\n",
    "b.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# क्या हाल है \n",
    "# توهان ڪيئن آهيو \n",
    "# আপনি কেমন আছেন \n",
    "# நீங்கள் எப்படி இருக்கிறீர்கள் \n",
    "# तिमीलाई कस्तो छ \n",
    "# તમે કેમ છો \n",
    "# तू कसा आहेस \n",
    "# ന്തൊക്കെയുണ്ട് \n",
    "# آپ کیسے ہو \n",
    "# ನೀವು ಹೇಗಿದ್ದೀರಿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams\n",
    "\n",
    "N-Grams refer to n combination of words in a sentence. For instance, for a sentence \"I love watching football\", some 2-grams would be (I love), (love watching) and (watching football). \n",
    "\n",
    "N-Grams can play a crucial role in text classification.\n",
    "\n",
    "The TextBlob.ngrams() method returns a list of tuples of n successive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"Now is better than never.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'than']),\n",
       " WordList(['better', 'than', 'never'])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet Integration\n",
    "\n",
    "WordNet is a database of English words that are linked together by their semantic relationships. It is like a supercharged dictionary/thesaurus with a graph structure.\n",
    "\n",
    "TextBlob 0.7 now integrates __NLTK's WordNet__ interface, making it very simple to interact with WordNet.\n",
    "\n",
    "### Synsets\n",
    "As you know, synonyms are words that have similar meanings. A synonym set, or synset, is a group of synonyms. A synset, therefore, corresponds to an abstract concept.\n",
    "\n",
    "In TextBlob, you can access the synsets that a word belongs to by accessing the synsets property of a Word object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('plant.n.01'),\n",
       " Synset('plant.n.02'),\n",
       " Synset('plant.n.03'),\n",
       " Synset('plant.n.04'),\n",
       " Synset('plant.v.01'),\n",
       " Synset('implant.v.01'),\n",
       " Synset('establish.v.02'),\n",
       " Synset('plant.v.04'),\n",
       " Synset('plant.v.05'),\n",
       " Synset('plant.v.06')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "word = Word(\"plant\")\n",
    "word.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buildings for carrying on industrial labor',\n",
       " '(botany) a living organism lacking the power of locomotion',\n",
       " 'an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience',\n",
       " 'something planted secretly for discovery by another',\n",
       " 'put or set (seeds, seedlings, or plants) into the ground',\n",
       " 'fix or set securely or deeply',\n",
       " 'set up or lay the groundwork for',\n",
       " 'place into a river',\n",
       " 'place something or someone in a certain position in order to secretly observe or deceive',\n",
       " 'put firmly in the mind']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant = word.synsets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The synonyms contained within a synset are called lemmas. You can access the string versions of these synonyms via a Synset's lemma_names property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Synset.lemma_names of Synset('plant.n.02')>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plant.lemma_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Upper and Lowercase\n",
    "TextBlob objects are very similar to strings. You can convert them to upper case or lower case, change their values, and concatenate them together as well. In the following script, we convert the text from the TextBlob object to upper case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I LOVE TO WATCH FOOTBALL, BUT I HAVE NEVER PLAYED IT\n"
     ]
    }
   ],
   "source": [
    "text = \"I love to watch football, but I have never played it\"\n",
    "text_blob_object = TextBlob(text)\n",
    "\n",
    "print(text_blob_object.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love to watch football, but i have never played it\n"
     ]
    }
   ],
   "source": [
    "text = \"I LOVE TO WATCH FOOTBALL, BUT I HAVE NEVER PLAYED IT\"\n",
    "text_blob_object = TextBlob(text)\n",
    "\n",
    "print(text_blob_object.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "The sentiment property returns a named tuple of the form Sentiment(polarity, subjectivity). \n",
    "\n",
    "The polarity score is a float within the range [-1.0, 1.0]. \n",
    "\n",
    "The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "Polarity is a float value within the range [-1.0 to 1.0] where \n",
    "\n",
    "    0 indicates neutral, \n",
    "    +1 indicates a very positive sentiment and \n",
    "    -1 represents a very negative sentiment.\n",
    "\n",
    "Subjectivity is a float value within the range [0.0 to 1.0] where \n",
    "\n",
    "    0.0 is very objective and \n",
    "    1.0 is very subjective. \n",
    "\n",
    "Subjective sentence expresses some personal feelings, views, beliefs, opinions, allegations, desires, beliefs, suspicions, and speculations \n",
    "\n",
    "where as Objective sentences are factual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimonial1 = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "testimonial2 = TextBlob(\"Earth is sphere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:  Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)\n",
      "Sentiment:  Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "print('Sentiment: ', testimonial1.sentiment)\n",
    "print('Sentiment: ', testimonial2.sentiment)\n",
    "\n",
    "#print('Polarity: ', testimonial1.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = TextBlob('Earth')\n",
    "word.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:  Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Polarity:  0.0\n"
     ]
    }
   ],
   "source": [
    "# DLSA (Document level sentiment Analysis)\n",
    "\n",
    "print('Sentiment: ', zen.sentiment)\n",
    "print('Polarity: ', zen.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "# SLSA (Sentence level sentiment analysis)\n",
    "for sentence in zen.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Text Classification System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some classifiers...\n",
    "\n",
    "    class textblob.classifiers.BaseClassifier\n",
    "    class textblob.classifiers.DecisionTreeClassifier\n",
    "    class textblob.classifiers.MaxEntClassifier\n",
    "    class textblob.classifiers.NLTKClassifier\n",
    "    class textblob.classifiers.NaiveBayesClassifier\n",
    "    class textblob.classifiers.PositiveNaiveBayesClassifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some training and test data.\n",
    "train = [\n",
    "     ('I love this sandwich.', 'pos'),\n",
    "     ('this is an amazing place!', 'pos'),\n",
    "     ('I feel very good about these beers.', 'pos'),\n",
    "     ('this is my best work.', 'pos'),\n",
    "     (\"what an awesome view\", 'pos'),\n",
    "     ('I do not like this restaurant', 'neg'),\n",
    "     ('I am tired of this stuff.', 'neg'),\n",
    "     (\"I can't deal with this\", 'neg'),\n",
    "     ('he is my sworn enemy!', 'neg'),\n",
    "     ('my boss is horrible.', 'neg')\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "     ('the beer was good.', 'pos'),\n",
    "     ('I do not enjoy my job', 'neg'),\n",
    "     (\"I ain't feeling dandy today.\", 'neg'),\n",
    "     (\"I feel amazing!\", 'pos'),\n",
    "     ('Gary is a friend of mine.', 'pos'),\n",
    "     (\"I can't believe I'm doing this.\", 'neg')\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data from Files\n",
    "# You can also load data from common file formats including CSV, JSON, and TSV.\n",
    "\n",
    "# CSV files should be formatted like so:\n",
    "\n",
    "# I love this sandwich.,pos\n",
    "# This is an amazing place!,pos\n",
    "# I do not like this restaurant,neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifying Text\n",
    "# Call the classify(text) method to use the classifier.\n",
    "\n",
    "cl.classify(\"This is an worst library!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get the label probability distribution with the prob_classify(text) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dist = cl.prob_classify(\"This one's a doozy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(prob_dist.prob(\"pos\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(prob_dist.prob(\"neg\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating Classifiers\n",
    "# To compute the accuracy on our test set, use the accuracy(test_data) method.\n",
    "\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the show_informative_features() method to display a listing of the most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(my) = True              neg : pos    =      1.7 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = True              neg : pos    =      1.4 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n",
      "            contains(my) = False             pos : neg    =      1.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Classifiers with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [('She is my best friend.', 'pos'),\n",
    "             (\"I'm happy to have a new friend.\", 'pos'),\n",
    "             (\"Stay thirsty, my friend.\", 'pos'),\n",
    "             (\"He ain't from around here.\", 'neg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.update(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
